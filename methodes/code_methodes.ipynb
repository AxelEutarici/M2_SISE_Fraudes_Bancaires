{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123d2a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\pauli\\Documents\\M2\\fouille de données\\projet\\fichiers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fddc2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/541795256308840198', creation_time=1673438592181, experiment_id='541795256308840198', last_update_time=1673438592181, lifecycle_stage='active', name='Fouilles de Données Massives', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "#rendre silencieux les messages du GIT\n",
    "os.environ[\"GIT_PYTHON_REFRESH\"] = \"quiet\"\n",
    "#définir une expérimentation\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Fouilles de Données Massives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36ca012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#lib de pre-process\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#lib de metriques\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix, f1_score, make_scorer, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b054a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_clean.csv', sep=\",\")\n",
    "index_train = pd.read_csv('index_train.csv',sep=\",\")\n",
    "index_train = index_train[\"0\"].values.tolist()\n",
    "index_test = pd.read_csv('index_test.csv',sep=\",\")\n",
    "index_test = index_test[\"0\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5848280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prendre moins de lignes ??? ou l'under sampling suffira ??? \n",
    "index_train30 = random.sample(index_train, round(len(index_train)*0.03))\n",
    "index_test30 = random.sample(index_test, round(len(index_test)*0.03))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d5e8a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,\"FlagImpaye\"]\n",
    "# Drop the 'FlagImpaye' column\n",
    "X = df.drop('FlagImpaye', axis=1)\n",
    "\n",
    "#ytrain\n",
    "ytrain = y.loc[index_train,]\n",
    "ytrain30 = y.loc[index_train30,]\n",
    "#ytest\n",
    "ytest = y.loc[index_test,]\n",
    "ytest30 = y.loc[index_test30,]\n",
    "#Xtrain\n",
    "Xtrain = X.loc[index_train,]\n",
    "Xtrain30 = X.loc[index_train30,]\n",
    "#Xtest\n",
    "Xtest = X.loc[index_test,]\n",
    "Xtest30 = X.loc[index_test30,]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13435913",
   "metadata": {},
   "source": [
    "## Retravailler le dataset d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f75116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 91491, 1: 448})\n"
     ]
    }
   ],
   "source": [
    "#undersampling with tomek-link\n",
    "from collections import Counter\n",
    "print('Original dataset shape %s' % Counter(ytrain))\n",
    "print('0.03 dataset shape %s' % Counter(ytrain30))\n",
    "\n",
    "tl = TomekLinks()\n",
    "Xtrain_tl, ytrain_tl = tl.fit_resample(Xtrain, ytrain)\n",
    "print('Tomeklinks resampled original dataset shape %s' % Counter(ytrain_tl))\n",
    "\n",
    "sm = SMOTE(sampling_strategy=0.5, k_neighbors=5, random_state=1)\n",
    "Xtrain_smote, ytrain_smote = sm.fit_resample(Xtrain30, ytrain30)\n",
    "print('Smote resampled 0.03 dataset shape %s' % Counter(ytrain_smote))\n",
    "\n",
    "#les 2...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83315372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normaliser \n",
    "normalizer = Normalizer() \n",
    "normalizer.fit(Xtrain)    \n",
    "Xtrain = normalizer.transform(Xtrain)\n",
    "Xtest = normalizer.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectionner des variables avec un algorithme filtre/ ranking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47ce605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain= Xtrain30.reset_index(drop=True)\n",
    "ytrain= ytrain30.reset_index(drop=True)\n",
    "Xtest= Xtest30.reset_index(drop=True)\n",
    "ytest= ytest30.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf61d5f7",
   "metadata": {},
   "source": [
    "## Boucle de recherche sur meilleur modele avec les meilleurs hyperparametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11c0db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Fouilles de Données Massives\")\n",
    "\n",
    "seed = 1\n",
    "\n",
    "# On stocke ci-dessous les valeurs des hyper-paramètres que l'on souhaite tester\n",
    "#np.arange(start = 5, stop = 250, step = 50)\n",
    "params_modeles = [\n",
    "{'criterion':['gini'], \n",
    " 'max_features':[3]},\n",
    "{\"solver\":[\"newton-cg\"],\n",
    " \"penalty\":[\"none\"],\n",
    " \"max_iter\":[10]}\n",
    "]\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "modeles_list = [\n",
    "    DecisionTreeClassifier(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "def select_model(modeles, parameters, Xtrain, ytrain, Xtest, ytest) :\n",
    "    df = pd.DataFrame(columns = ['best','score', 'ftest', 'ftrain', 'lr_auc', 'time_train'])    \n",
    "    \n",
    "    for i, modele in enumerate(modeles):\n",
    "        modele_name = str(modele)\n",
    "        \n",
    "        #start run mlflow\n",
    "        my_run = mlflow.start_run(run_name = modele_name)\n",
    "        \n",
    "        f1 = make_scorer(f1_score , average='macro')\n",
    "        #test all models with CV\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        model = GridSearchCV(estimator=modele,\n",
    "                            param_grid=parameters[i],\n",
    "                            scoring = f1,\n",
    "                            verbose = False,\n",
    "                            cv = 3)\n",
    "        start_time = time.time()\n",
    "        model.fit(Xtrain, ytrain)\n",
    "        full_time = time.time() - start_time\n",
    "        \n",
    "        rankTrain = model.predict(Xtrain)\n",
    "        rankTest = model.predict(Xtest)\n",
    "\n",
    "        #calcul metrics\n",
    "        #calcul de la f-mesure pour mesurer la performance du modele \n",
    "        ctrain = confusion_matrix(ytrain, rankTrain)\n",
    "        ftrain = round(2*ctrain[1,1]/(2*ctrain[1,1]+ctrain[0,1]+ctrain[1,0]),4)\n",
    "        ctest = confusion_matrix(ytest, rankTest)\n",
    "        ftest = round(2*ctest[1,1]/(2*ctest[1,1]+ctest[0,1]+ctest[1,0]),4)\n",
    "        #calcul de l-AUC Precision-Rappel\n",
    "        lr_precision, lr_recall, _ = precision_recall_curve(ytest, rankTest)\n",
    "        lr_auc =  auc(lr_recall, lr_precision)\n",
    "        \n",
    "        #df with all indicators\n",
    "        df.loc[i]=[model.best_estimator_, model.best_score_, ftest, ftrain, lr_auc, full_time]\n",
    "        \n",
    "        #save info i mlflow\n",
    "        mlflow.sklearn.log_model(modele,modele_name)\n",
    "        #artifact\n",
    "        #mlflow.log_artifact(\"guillaume.txt\")\n",
    "        #stocker les métriques\n",
    "        my_run.metrics = {}\n",
    "        #rajout des éléments de performance\n",
    "        my_run.metrics['best'] = model.best_score_\n",
    "        my_run.metrics['ftest'] = ftest\n",
    "        my_run.metrics['ftrain'] = ftrain\n",
    "        my_run.metrics['lr_auc']= lr_auc\n",
    "        my_run.metrics['full_time']=full_time\n",
    "        mlflow.log_metrics(my_run.metrics)\n",
    "        #paramètres de l'algo\n",
    "        mlflow.log_params(modele.get_params())\n",
    "        mlflow.end_run()\n",
    "        \n",
    "    #return df with all indicators  \n",
    "    return df\n",
    "\n",
    "df_ind = select_model(modeles_list, params_modeles, Xtrain, ytrain, Xtest, ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c557bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26155003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best</th>\n",
       "      <th>score</th>\n",
       "      <th>ftest</th>\n",
       "      <th>ftrain</th>\n",
       "      <th>lr_auc</th>\n",
       "      <th>time_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier(max_features=3)</td>\n",
       "      <td>0.519712</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044076</td>\n",
       "      <td>2.078820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(max_iter=10, penalty='none'...</td>\n",
       "      <td>0.498667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504616</td>\n",
       "      <td>3.189483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                best     score   ftest  \\\n",
       "0             DecisionTreeClassifier(max_features=3)  0.519712  0.0378   \n",
       "1  LogisticRegression(max_iter=10, penalty='none'...  0.498667  0.0000   \n",
       "\n",
       "   ftrain    lr_auc  time_train  \n",
       "0     1.0  0.044076    2.078820  \n",
       "1     0.0  0.504616    3.189483  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091168bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#appliquer et sauvegarder le meilleur modele\n",
    "#get index of df wich have best f1 score\n",
    "indice=df_ind['ftest'].idxmax()\n",
    "#keep model with best f score\n",
    "best_model = df_ind[\"best\"][indice]\n",
    "best_model.fit(X, y)\n",
    "pickle.dump(best_model, open(\"./model.pickle.dat\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72025428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost/ gradient tree boosting \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "param = {\"loss\":\"log_loss\",\"learning_rate\":0.1,\"n_estimators\":100,\"min_samples_split\":2}\n",
    "gbc = GradientBoostingClassifier(loss=\"log_loss\", learning_rate=0.1, n_estimators=100, min_samples_split=2)\n",
    "gbc.fit(Xtrain, ytrain)\n",
    "\n",
    "#Nearest-Neighbor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier(n_neighbors=2, algorithm='ball_tree')\n",
    "knc.fit(Xtrain, ytrain)\n",
    "\n",
    "#Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "param = {\"criterion\":\"gini\",\"max_depth\":None,\"min_samples_split\":2,\"min_samples_leaf\":1,\"max_features\":\"sqrt\"}\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc = dtc.fit(Xtrain, ytrain)\n",
    "\n",
    "#Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param = {\"n_estimators\":100,\"criterion\":\"gini\",\"max_depth\":None,\"min_samples_split\":2,\"min_samples_leaf\":1,\"max_features\":\"sqrt\",\"oob_score\":False,\"warm_start\":False,\"max_samples\":None}\n",
    "rfc = RandomForestClassifier()\n",
    "rfc = rfc.fit(Xtrain, ytrain)\n",
    "\n",
    "#SVM\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "param = {\"kernel\":\"rbf\",\"degree\":3,}\n",
    "#ici on peut changer le noyaux\n",
    "svc = make_pipeline(StandardScaler(), SVC(kernel=\"rbf\",degree=3))\n",
    "svc.fit(Xtrain, ytrain)\n",
    "\n",
    "#K-means\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\")\n",
    "kmeans.fit(Xtrain)\n",
    "#bof ca, on ne prend meme pas en compte les y...\n",
    "\n",
    "\n",
    "#LOF\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "lof = LocalOutlierFactor(n_neighbors=2)\n",
    "lof.fit(Xtrain)\n",
    "\n",
    "#Auto-encodeurs\n",
    "#keskecé ???\n",
    "\n",
    "#Reseaux de neurones\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlpc = MLPClassifier(random_state=1, max_iter=100)\n",
    "mlpc.fit(Xtrain, ytrain)\n",
    "\n",
    "#ADL\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "adl = LinearDiscriminantAnalysis()\n",
    "adl.fit(Xtrain, ytrain)\n",
    "\n",
    "#ADQ\n",
    "from sklearn.qda import QDA\n",
    "qda = QDA()\n",
    "qda.fit(Xtrain, ytrain)\n",
    "\n",
    "#Cost-sensitive learning\n",
    "#On pondère les erreurs \n",
    "#Modifier le poids de chaque classe sur le substitue de taux d’erreur \n",
    "#Attribuer un poids a chaque entrée de la matrice de confusion (cout a l’échelle de chaque classe) \n",
    "\n",
    "#Methodes ensemblistes\n",
    "#bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "param = {\"max_features\":0.5,\"max_samples\" : 0.5}\n",
    "bagging = BaggingClassifier(KNeighborsClassifier())\n",
    "\n",
    "#boosting \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "adab = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(adab, Xtrain, ytrain, cv=5)\n",
    "\n",
    "#regression logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param = {\"solver\":\"saga\",\"penalty\":\"none\",\"max_iter\":100}\n",
    "logit = LogisticRegression(solver=\"saga\", penalty=\"none\", max_iter=100, random_state=1)\n",
    "logit.fit(Xtrain, ytrain)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9c343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
